### (1) Валидационный набор

> Идея: Cчитать ошибку на подвыборке, на которой не обучались (обычно 10-30% от исх.)

Генерировать val мы можем:
+ рандомно
+ со стратификацией (по признаку или отклику)
+ с сохранением пропорции кластеров

Ошибку на val выборке называют **HoldOut ошибка**.

> Итог: Самая простая, но не самая объективная оценка, т.к. зависит от рандома(риск излишнего оптимизма) и модель обучается не на всех данных.

---
### (2) Кросс-валидация. CV

> Идея: Разбить выборку на части, каждая из которых будет один раз заменять val выборку, т.е. получить много моделей и более объективную оценку гиперпараметров.

Рандомно (или со стратификацией) разбиваем выборку на n подвыборок. Каждая из подвыборок один раз выступает в качестве val выборки, а оставшиеся как train. Получаем n моделей, n оценок.

**CV-ошибка** = среднее среди n оценок ошибки.

> Итог: Получили лучшую оценку гиперпараметров(, НО не лучшую модель).

---
### (2.1) LOOCV (Leave-One-Out Cross-Validation)

> Идея: Крайний случай кросс-валидации, где каждый объект по очереди становится валидационной выборкой.

- CV = среднее по всем возможным train-val разбиениям
- Особенно рекомендуется для маленьких выборок
- Вычислительно дорогой (нужно построить n моделей)

> Итог: Максимально использует данные для оценки, но может быть нестабильным.

---
### (2.2) CV для выбора метапараметров

>[!point] RandomSearchCV

> Идея: Случайный поиск гиперпараметров (быстрый, но без гарантий оптимальности)

- Быстрее полного перебора (GridSearchCV)
- Не гарантирует нахождение глобального оптимума
- Эффективен при большом количестве параметров

> Итог: Быстрый способ подбора параметров, но результаты могут быть нестабильными.

>[!point] Latin Hypercube Sampling

> Идея: Систематический подход к случайному выбору точек в пространстве параметров.

- Разбиваем диапазон каждого признака на n интервалов
- Случайно выбираем точки так, чтобы они не попадали в уже занятые интервалы
- За n шагов покрываем всё пространство параметров

> Итог: Более равномерное покрытие пространства параметров по сравнению с pure RandomSearch.

>[!point] Эволюционные алгоритмы (EA)

> Идея: Лучшие решения выживают в следующих поколениях

1. Создаём начальную популяцию (случайные комбинации параметров)
2. Отбираем лучшие решения (родителей)
3. Скрещиваем (получаем детей) и мутируем (детей или родителей)
4. Повторяем процесс, пока не достигнем критерия остановки (например, числа поколений)

> Итог: Мощный метод для сложных пространств параметров, но требует больше вычислений.

>[!point] Байесовская оптимизация

> Идея: Использование предыдущих результатов для выбора следующих точек поиска.

- Начинаем с нескольких случайных комбинаций
- Строим вероятностную модель (суррогатную функцию)
- Выбираем следующие точки из областей, где метрики или неопределенность выше.

> Итог: Эффективный метод, особенно когда оценка качества модели дорогая.

>[!point] Halving GridSearchCV - хороший выбор

> Идея: Оптимизированный вариант GridSearch с последовательным сокращением количества кандидатов

- На каждом этапе оставляем лучшие 50% вариантов
- Начальный этап: перебор всех комбинаций параметров на маленькой подвыборке (1%)
- Постепенное увеличение подвыборки (1% → 10% → 50% → ...)

> Итог: Более эффективный по сравнению с обычным GridSearch, но требует подготовки технических параметров

>[!point] Halving RandomSearchCV

> Идея: Комбинация RandomSearch с последовательным отбором лучших параметров

- Аналогично Halving GridSearch, но с случайным подбором
- Особенно эффективен для комплексных параметров
- Учитывает распределительные характеристики системы

> Итог: Баланс между скоростью RandomSearch и точностью последовательного отбора

---
### (3) Бутстреппинг

> Оценка на основе подвыборок "с возвращением".

+ Формируем подвыборки "с возвращением". Допускается дублирование наблюдений в подвыборке или их отсутствие.
+ На этих подвыборках можно обучать модели (бэггинг) или считать статистики, а результат усреднять.
+ Наблюдения не попавшие в подвыборку конкретной модели можно использовать для валидации этой модели (OutOfBag OOB-оценка).
> Итог: Бутстреппинг позволяет получать не только точечную оценку но и распределения (например, распределение средних по подвыборкам стоимости домов в Москве (дальше можно например строить квантили и делать выводы по типу "Стоимость дома в москве лежит в диапазоне (a, b) с вер-тью 95% ... ") )